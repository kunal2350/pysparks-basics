{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a spark session\n",
    "spark=SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-ADT8F0B:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x28476337898>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing a dataset and considering the 1st row as column header. \n",
    "df_pyspark=spark.read.csv(r\"C:\\Users\\kunal\\Desktop\\Github projects\\studentNames.csv\",header=True, inferSchema=True)\n",
    "#If inferSchema=False, it will consider all the values as string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing on the dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Roll No.=1, Surname='Chauhan', Name='Paridhee', Father='P.', Age=1),\n",
       " Row(Roll No.=2, Surname='Desai', Name='Yashvi', Father='R.', Age=2),\n",
       " Row(Roll No.=3, Surname='Dheriwala', Name='Bibi Fatema', Father='Mo. J.', Age=3)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)\n",
    "#output is in list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Roll No.: int, Surname: string, Name: string, Father: string, Age: int]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing schema of dataset\n",
    "df_pyspark.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Roll No.', 'Surname', 'Name', 'Father', 'Age']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       Name|\n",
      "+-----------+\n",
      "|   Paridhee|\n",
      "|     Yashvi|\n",
      "|Bibi Fatema|\n",
      "|      Vidhi|\n",
      "|      Manya|\n",
      "|    Trishvi|\n",
      "|      Tithi|\n",
      "|       Heer|\n",
      "|       Keya|\n",
      "|     Krisha|\n",
      "|      Navya|\n",
      "|     Riddhi|\n",
      "|    Hirisha|\n",
      "|    Ridhima|\n",
      "|       Heer|\n",
      "|       Mahi|\n",
      "|      Divya|\n",
      "|       Viva|\n",
      "|      Aarya|\n",
      "|      Aarya|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('Name')\n",
    "df_pyspark.select('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|       Name|  Surname|\n",
      "+-----------+---------+\n",
      "|   Paridhee|  Chauhan|\n",
      "|     Yashvi|    Desai|\n",
      "|Bibi Fatema|Dheriwala|\n",
      "|      Vidhi| Ghadiali|\n",
      "|      Manya|  Kapadia|\n",
      "|    Trishvi|  Panchal|\n",
      "|      Tithi|   Pandya|\n",
      "|       Heer|    Patel|\n",
      "|       Keya|    Patel|\n",
      "|     Krisha|    Patel|\n",
      "|      Navya|    Patel|\n",
      "|     Riddhi|    Patel|\n",
      "|    Hirisha|   Pithva|\n",
      "|    Ridhima|Prajapati|\n",
      "|       Heer|  Purohit|\n",
      "|       Mahi| Rajpriya|\n",
      "|      Divya|  Rathava|\n",
      "|       Viva|  Sanghvi|\n",
      "|      Aarya|     Shah|\n",
      "|      Aarya|     Shah|\n",
      "+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('Name','Surname').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Roll No.', 'int'),\n",
       " ('Surname', 'string'),\n",
       " ('Name', 'string'),\n",
       " ('Father', 'string'),\n",
       " ('Age', 'int')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+-----+------+------------------+\n",
      "|summary|          Roll No.|Surname| Name|Father|               Age|\n",
      "+-------+------------------+-------+-----+------+------------------+\n",
      "|  count|                62|     62|   62|    62|                59|\n",
      "|   mean|              31.5|   null| null|  null|31.983050847457626|\n",
      "| stddev|18.041618552668716|   null| null|  null|18.215654053610542|\n",
      "|    min|                 1|   Amin|Aarav|    A.|                 1|\n",
      "|    max|                62|  Yadav| Zain|    Z.|                62|\n",
      "+-------+------------------+-------+-----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding column in dataframe\n",
    "df_pyspark=df_pyspark.withColumn('Age+2',df_pyspark['Age']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| Age|Age+2|\n",
      "+----+-----+\n",
      "|   1|    3|\n",
      "|   2|    4|\n",
      "|   3|    5|\n",
      "|   4|    6|\n",
      "|   5|    7|\n",
      "|   6|    8|\n",
      "|   7|    9|\n",
      "|   8|   10|\n",
      "|   9|   11|\n",
      "|  10|   12|\n",
      "|null| null|\n",
      "|  12|   14|\n",
      "|  13|   15|\n",
      "|  14|   16|\n",
      "|  15|   17|\n",
      "|  16|   18|\n",
      "|  17|   19|\n",
      "|  18|   20|\n",
      "|null| null|\n",
      "|  20|   22|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('Age','Age+2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+------+----+\n",
      "|Roll No.|  Surname|       Name|Father| Age|\n",
      "+--------+---------+-----------+------+----+\n",
      "|       1|  Chauhan|   Paridhee|    P.|   1|\n",
      "|       2|    Desai|     Yashvi|    R.|   2|\n",
      "|       3|Dheriwala|Bibi Fatema|Mo. J.|   3|\n",
      "|       4| Ghadiali|      Vidhi|    M.|   4|\n",
      "|       5|  Kapadia|      Manya|    J.|   5|\n",
      "|       6|  Panchal|    Trishvi|    A.|   6|\n",
      "|       7|   Pandya|      Tithi|    M.|   7|\n",
      "|       8|    Patel|       Heer|    V.|   8|\n",
      "|       9|    Patel|       Keya|    J.|   9|\n",
      "|      10|    Patel|     Krisha|    N.|  10|\n",
      "|      11|    Patel|      Navya|    J.|null|\n",
      "|      12|    Patel|     Riddhi|    D.|  12|\n",
      "|      13|   Pithva|    Hirisha|    S.|  13|\n",
      "|      14|Prajapati|    Ridhima|    J.|  14|\n",
      "|      15|  Purohit|       Heer|    M.|  15|\n",
      "|      16| Rajpriya|       Mahi|    B.|  16|\n",
      "|      17|  Rathava|      Divya|    N.|  17|\n",
      "|      18|  Sanghvi|       Viva|    N.|  18|\n",
      "|      19|     Shah|      Aarya|    D.|null|\n",
      "|      20|     Shah|      Aarya|    J.|  20|\n",
      "+--------+---------+-----------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropping columns from dataframe\n",
    "df_pyspark=df_pyspark.drop('Age+2')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+------+----+\n",
      "|Roll No.|  Surname| First Name|Father| Age|\n",
      "+--------+---------+-----------+------+----+\n",
      "|       1|  Chauhan|   Paridhee|    P.|   1|\n",
      "|       2|    Desai|     Yashvi|    R.|   2|\n",
      "|       3|Dheriwala|Bibi Fatema|Mo. J.|   3|\n",
      "|       4| Ghadiali|      Vidhi|    M.|   4|\n",
      "|       5|  Kapadia|      Manya|    J.|   5|\n",
      "|       6|  Panchal|    Trishvi|    A.|   6|\n",
      "|       7|   Pandya|      Tithi|    M.|   7|\n",
      "|       8|    Patel|       Heer|    V.|   8|\n",
      "|       9|    Patel|       Keya|    J.|   9|\n",
      "|      10|    Patel|     Krisha|    N.|  10|\n",
      "|      11|    Patel|      Navya|    J.|null|\n",
      "|      12|    Patel|     Riddhi|    D.|  12|\n",
      "|      13|   Pithva|    Hirisha|    S.|  13|\n",
      "|      14|Prajapati|    Ridhima|    J.|  14|\n",
      "|      15|  Purohit|       Heer|    M.|  15|\n",
      "|      16| Rajpriya|       Mahi|    B.|  16|\n",
      "|      17|  Rathava|      Divya|    N.|  17|\n",
      "|      18|  Sanghvi|       Viva|    N.|  18|\n",
      "|      19|     Shah|      Aarya|    D.|null|\n",
      "|      20|     Shah|      Aarya|    J.|  20|\n",
      "+--------+---------+-----------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#renaming a column name\n",
    "df_pyspark=df_pyspark.withColumnRenamed('Name','First Name')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.drop('Roll No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------+---+\n",
      "|  Surname| First Name|Father|Age|\n",
      "+---------+-----------+------+---+\n",
      "|  Chauhan|   Paridhee|    P.|  1|\n",
      "|    Desai|     Yashvi|    R.|  2|\n",
      "|Dheriwala|Bibi Fatema|Mo. J.|  3|\n",
      "| Ghadiali|      Vidhi|    M.|  4|\n",
      "|  Kapadia|      Manya|    J.|  5|\n",
      "|  Panchal|    Trishvi|    A.|  6|\n",
      "|   Pandya|      Tithi|    M.|  7|\n",
      "|    Patel|       Heer|    V.|  8|\n",
      "|    Patel|       Keya|    J.|  9|\n",
      "|    Patel|     Krisha|    N.| 10|\n",
      "|    Patel|     Riddhi|    D.| 12|\n",
      "|   Pithva|    Hirisha|    S.| 13|\n",
      "|Prajapati|    Ridhima|    J.| 14|\n",
      "|  Purohit|       Heer|    M.| 15|\n",
      "| Rajpriya|       Mahi|    B.| 16|\n",
      "|  Rathava|      Divya|    N.| 17|\n",
      "|  Sanghvi|       Viva|    N.| 18|\n",
      "|     Shah|      Aarya|    J.| 20|\n",
      "|     Shah|    Srushti|    H.| 21|\n",
      "|   Shukla|   Yajashvi|    V.| 22|\n",
      "+---------+-----------+------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###dropping rows having atleast one null values\n",
    "df_pyspark1=df_pyspark.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------+----+\n",
      "|  Surname| First Name|Father| Age|\n",
      "+---------+-----------+------+----+\n",
      "|  Chauhan|   Paridhee|    P.|   1|\n",
      "|    Desai|     Yashvi|    R.|   2|\n",
      "|Dheriwala|Bibi Fatema|Mo. J.|   3|\n",
      "| Ghadiali|      Vidhi|    M.|   4|\n",
      "|  Kapadia|      Manya|    J.|   5|\n",
      "|  Panchal|    Trishvi|    A.|   6|\n",
      "|   Pandya|      Tithi|    M.|   7|\n",
      "|    Patel|       Heer|    V.|   8|\n",
      "|    Patel|       Keya|    J.|   9|\n",
      "|    Patel|     Krisha|    N.|  10|\n",
      "|    Patel|      Navya|    J.|null|\n",
      "|    Patel|     Riddhi|    D.|  12|\n",
      "|   Pithva|    Hirisha|    S.|  13|\n",
      "|Prajapati|    Ridhima|    J.|  14|\n",
      "|  Purohit|       Heer|    M.|  15|\n",
      "| Rajpriya|       Mahi|    B.|  16|\n",
      "|  Rathava|      Divya|    N.|  17|\n",
      "|  Sanghvi|       Viva|    N.|  18|\n",
      "|     Shah|      Aarya|    D.|null|\n",
      "|     Shah|      Aarya|    J.|  20|\n",
      "+---------+-----------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###dropping rows having all null values\n",
    "df_pyspark2=df_pyspark.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------+----+\n",
      "|  Surname| First Name|Father| Age|\n",
      "+---------+-----------+------+----+\n",
      "|  Chauhan|   Paridhee|    P.|   1|\n",
      "|    Desai|     Yashvi|    R.|   2|\n",
      "|Dheriwala|Bibi Fatema|Mo. J.|   3|\n",
      "| Ghadiali|      Vidhi|    M.|   4|\n",
      "|  Kapadia|      Manya|    J.|   5|\n",
      "|  Panchal|    Trishvi|    A.|   6|\n",
      "|   Pandya|      Tithi|    M.|   7|\n",
      "|    Patel|       Heer|    V.|   8|\n",
      "|    Patel|       Keya|    J.|   9|\n",
      "|    Patel|     Krisha|    N.|  10|\n",
      "|    Patel|      Navya|    J.|null|\n",
      "|    Patel|     Riddhi|    D.|  12|\n",
      "|   Pithva|    Hirisha|    S.|  13|\n",
      "|Prajapati|    Ridhima|    J.|  14|\n",
      "|  Purohit|       Heer|    M.|  15|\n",
      "| Rajpriya|       Mahi|    B.|  16|\n",
      "|  Rathava|      Divya|    N.|  17|\n",
      "|  Sanghvi|       Viva|    N.|  18|\n",
      "|     Shah|      Aarya|    D.|null|\n",
      "|     Shah|      Aarya|    J.|  20|\n",
      "+---------+-----------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###dropping rows having less than threshold number of non null values\n",
    "df_pyspark3=df_pyspark.dropna(how=\"any\",thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------+---+\n",
      "|  Surname| First Name|Father|Age|\n",
      "+---------+-----------+------+---+\n",
      "|  Chauhan|   Paridhee|    P.|  1|\n",
      "|    Desai|     Yashvi|    R.|  2|\n",
      "|Dheriwala|Bibi Fatema|Mo. J.|  3|\n",
      "| Ghadiali|      Vidhi|    M.|  4|\n",
      "|  Kapadia|      Manya|    J.|  5|\n",
      "|  Panchal|    Trishvi|    A.|  6|\n",
      "|   Pandya|      Tithi|    M.|  7|\n",
      "|    Patel|       Heer|    V.|  8|\n",
      "|    Patel|       Keya|    J.|  9|\n",
      "|    Patel|     Krisha|    N.| 10|\n",
      "|    Patel|     Riddhi|    D.| 12|\n",
      "|   Pithva|    Hirisha|    S.| 13|\n",
      "|Prajapati|    Ridhima|    J.| 14|\n",
      "|  Purohit|       Heer|    M.| 15|\n",
      "| Rajpriya|       Mahi|    B.| 16|\n",
      "|  Rathava|      Divya|    N.| 17|\n",
      "|  Sanghvi|       Viva|    N.| 18|\n",
      "|     Shah|      Aarya|    J.| 20|\n",
      "|     Shah|    Srushti|    H.| 21|\n",
      "|   Shukla|   Yajashvi|    V.| 22|\n",
      "+---------+-----------+------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###dropping the rows which have null is a specified column\n",
    "df_pyspark4=df_pyspark.dropna(how=\"any\",subset=['Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing/null values\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=['Age'],\n",
    "                  outputCols=[\"{}_imputed\".format(c) for c in ['Age']]).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------+----+-----------+\n",
      "|  Surname| First Name|Father| Age|Age_imputed|\n",
      "+---------+-----------+------+----+-----------+\n",
      "|  Chauhan|   Paridhee|    P.|   1|          1|\n",
      "|    Desai|     Yashvi|    R.|   2|          2|\n",
      "|Dheriwala|Bibi Fatema|Mo. J.|   3|          3|\n",
      "| Ghadiali|      Vidhi|    M.|   4|          4|\n",
      "|  Kapadia|      Manya|    J.|   5|          5|\n",
      "|  Panchal|    Trishvi|    A.|   6|          6|\n",
      "|   Pandya|      Tithi|    M.|   7|          7|\n",
      "|    Patel|       Heer|    V.|   8|          8|\n",
      "|    Patel|       Keya|    J.|   9|          9|\n",
      "|    Patel|     Krisha|    N.|  10|         10|\n",
      "|    Patel|      Navya|    J.|null|         31|\n",
      "|    Patel|     Riddhi|    D.|  12|         12|\n",
      "|   Pithva|    Hirisha|    S.|  13|         13|\n",
      "|Prajapati|    Ridhima|    J.|  14|         14|\n",
      "|  Purohit|       Heer|    M.|  15|         15|\n",
      "| Rajpriya|       Mahi|    B.|  16|         16|\n",
      "|  Rathava|      Divya|    N.|  17|         17|\n",
      "|  Sanghvi|       Viva|    N.|  18|         18|\n",
      "|     Shah|      Aarya|    D.|null|         31|\n",
      "|     Shah|      Aarya|    J.|  20|         20|\n",
      "+---------+-----------+------+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Filter Operations</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+---+\n",
      "|  Surname|First Name|Father|Age|\n",
      "+---------+----------+------+---+\n",
      "|    Vohra|      Zain|    P.| 56|\n",
      "|     Dola|      Aban|    A.| 57|\n",
      "|Chaudhari|       Het|    V.| 58|\n",
      "|   Sheikh|    Tameem|    I.| 59|\n",
      "|  Solanki|     Aarav|    J.| 60|\n",
      "|    Jadav|      Neel|    K.| 61|\n",
      "|  Solanki|      Yami|    A.| 62|\n",
      "+---------+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#students with age more than 40\n",
    "df_pyspark.filter(df_pyspark['Age']>55).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|First Name|Age|\n",
      "+----------+---+\n",
      "|     Heyan| 41|\n",
      "|    Maitra| 42|\n",
      "|     Param| 43|\n",
      "|       Yug| 44|\n",
      "|      Neel| 45|\n",
      "|     Rudra| 46|\n",
      "|       Het| 47|\n",
      "|     Naksh| 48|\n",
      "|     Navya| 49|\n",
      "|     Herik| 50|\n",
      "|    Jenish| 51|\n",
      "|    Hetang| 52|\n",
      "|   Yashraj| 53|\n",
      "|   Dharmik| 54|\n",
      "|     Arman| 55|\n",
      "|      Zain| 56|\n",
      "|      Aban| 57|\n",
      "|       Het| 58|\n",
      "|    Tameem| 59|\n",
      "|     Aarav| 60|\n",
      "+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Age>40\").select(['First Name','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+---+\n",
      "|Surname|First Name|Father|Age|\n",
      "+-------+----------+------+---+\n",
      "|  Patel|     Heyan|    K.| 41|\n",
      "|  Patel|    Maitra|    N.| 42|\n",
      "|  Patel|     Param|    N.| 43|\n",
      "|  Patel|       Yug|    R.| 44|\n",
      "| Purani|      Neel|    S.| 45|\n",
      "| Rathod|     Rudra|    S.| 46|\n",
      "|   Shah|       Het|    B.| 47|\n",
      "|   Shah|     Naksh|    M.| 48|\n",
      "|   Shah|     Navya|    M.| 49|\n",
      "+-------+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#students with age more than 40 AND less than 50\n",
    "df_pyspark.filter((df_pyspark['Age']>40) & (df_pyspark['Age']<50)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------+---+\n",
      "|  Surname| First Name|Father|Age|\n",
      "+---------+-----------+------+---+\n",
      "|  Chauhan|   Paridhee|    P.|  1|\n",
      "|    Desai|     Yashvi|    R.|  2|\n",
      "|Dheriwala|Bibi Fatema|Mo. J.|  3|\n",
      "| Ghadiali|      Vidhi|    M.|  4|\n",
      "|    Vohra|       Zain|    P.| 56|\n",
      "|     Dola|       Aban|    A.| 57|\n",
      "|Chaudhari|        Het|    V.| 58|\n",
      "|   Sheikh|     Tameem|    I.| 59|\n",
      "|  Solanki|      Aarav|    J.| 60|\n",
      "|    Jadav|       Neel|    K.| 61|\n",
      "|  Solanki|       Yami|    A.| 62|\n",
      "+---------+-----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#students with age less than 5 OR more than 55\n",
    "df_pyspark.filter((df_pyspark['Age']>55) | (df_pyspark['Age']<5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------+---+\n",
      "|  Surname| First Name|Father|Age|\n",
      "+---------+-----------+------+---+\n",
      "|  Chauhan|   Paridhee|    P.|  1|\n",
      "|    Desai|     Yashvi|    R.|  2|\n",
      "|Dheriwala|Bibi Fatema|Mo. J.|  3|\n",
      "| Ghadiali|      Vidhi|    M.|  4|\n",
      "|  Kapadia|      Manya|    J.|  5|\n",
      "+---------+-----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inverse filter\n",
    "df_pyspark.filter(~(df_pyspark['Age']>5)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Group by and Aggregate function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "| Surname|sum(Age)|\n",
      "+--------+--------+\n",
      "|    Soni|      51|\n",
      "|   Yadav|      53|\n",
      "|  Purani|      45|\n",
      "|Dudhwala|      26|\n",
      "|  Kharva|      32|\n",
      "| Sanghvi|      18|\n",
      "|   Joshi|      31|\n",
      "| Vaghela|      23|\n",
      "|   Desai|       2|\n",
      "| Chauhan|       1|\n",
      "| Purohit|      15|\n",
      "|  Jadeja|      30|\n",
      "|  Sheikh|      59|\n",
      "| Kapadia|       5|\n",
      "|  Pandya|      96|\n",
      "|    Amin|      24|\n",
      "|Rajpriya|      16|\n",
      "|  Talati|      52|\n",
      "|   Jadav|      61|\n",
      "|    Shah|     185|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#groupby\n",
    "df_pyspark.groupBy('Surname').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "| Surname|avg(Age)|\n",
      "+--------+--------+\n",
      "|    Soni|    51.0|\n",
      "|   Yadav|    53.0|\n",
      "|  Purani|    45.0|\n",
      "|Dudhwala|    26.0|\n",
      "|  Kharva|    32.0|\n",
      "| Sanghvi|    18.0|\n",
      "|   Joshi|    31.0|\n",
      "| Vaghela|    23.0|\n",
      "|   Desai|     2.0|\n",
      "| Chauhan|     1.0|\n",
      "| Purohit|    15.0|\n",
      "|  Jadeja|    30.0|\n",
      "|  Sheikh|    59.0|\n",
      "| Kapadia|     5.0|\n",
      "|  Pandya|    32.0|\n",
      "|    Amin|    24.0|\n",
      "|Rajpriya|    16.0|\n",
      "|  Talati|    52.0|\n",
      "|   Jadav|    61.0|\n",
      "|    Shah|    37.0|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Surname').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(Age)|\n",
      "+--------+\n",
      "|    1887|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Age':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
